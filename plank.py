import cv2
import mediapipe as mp
import numpy as np
import os
import time
import threading
import queue
import subprocess
from typing import List, Dict, Tuple, Optional
from collections import Counter as GradeCounter
import json

# MediaPipe Pose ëª¨ë¸ ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

class UniversalTTS:
    """ëª¨ë“  í”Œë«í¼ì—ì„œ ì‘ë™í•˜ëŠ” TTS ì‹œìŠ¤í…œ (í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•)"""
    
    def __init__(self):
        self.feedback_queue = queue.Queue()
        self.last_feedback_time = {}  # ê° ì˜¤ë¥˜ë³„ ë§ˆì§€ë§‰ í”¼ë“œë°± ì‹œê°„
        self.feedback_cooldown = 3.0  # ê°™ì€ ì˜¤ë¥˜ì— ëŒ€í•œ í”¼ë“œë°± ì¿¨ë‹¤ìš´ (ì´ˆ)
        self.min_feedback_interval = 2.0  # ìµœì†Œ í”¼ë“œë°± ê°„ê²© (ì´ˆ)
        self.last_general_feedback = 0  # ë§ˆì§€ë§‰ ì¼ë°˜ í”¼ë“œë°± ì‹œê°„
        self.running = True
        self.feedback_thread = threading.Thread(target=self._feedback_worker, daemon=True)
        
        # í”Œë«í¼ë³„ TTS ì„¤ì •
        self.platform = self._detect_platform()
        self.setup_tts()
        
        # ì ¯ìŠ¨ì—ì„œ TTS ë„êµ¬ ì„¤ì¹˜ ì•ˆë‚´
        if self.platform == "Jetson":
            self._check_jetson_tts_tools()
        
        self.feedback_thread.start()
        
        # í”¼ë“œë°± ë©”ì‹œì§€ ë§¤í•‘
        self.feedback_messages = {
            "ì—‰ë©ì´ ì²˜ì§": "ì—‰ë©ì´ë¥¼ ë“¤ì–´ì˜¬ë¦¬ì„¸ìš”. í—ˆë¦¬ê°€ êº¾ì´ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.",
            "ì—‰ë©ì´ ì†ŸìŒ": "ì—‰ë©ì´ë¥¼ ë„ˆë¬´ ë†’ì´ ë“¤ì§€ ë§ˆì„¸ìš”. ëª¸ì„ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.",
            "ê³ ê°œ ì •ë ¬ ë¶ˆëŸ‰": "ê³ ê°œë¥¼ ë˜‘ë°”ë¡œ ìœ ì§€í•˜ì„¸ìš”. ëª©ì´ êº¾ì´ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.",
            "íŒ”ê¿ˆì¹˜ ì •ë ¬ ë¶ˆëŸ‰": "íŒ”ê¿ˆì¹˜ë¥¼ ì–´ê¹¨ ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜ì‹œí‚¤ì„¸ìš”.",
            "ë¬´ë¦ êµ½í˜": "ë‹¤ë¦¬ë¥¼ í´ê³  ê¸´ì¥ì„ ìœ ì§€í•˜ì„¸ìš”."
        }
    
    def _detect_platform(self):
        """í”Œë«í¼ ê°ì§€"""
        import platform
        system = platform.system()
        
        # ì ¯ìŠ¨ ê°ì§€ (ARM64 + Linux)
        if system == "Linux":
            try:
                with open('/proc/cpuinfo', 'r') as f:
                    cpu_info = f.read()
                    if 'aarch64' in cpu_info or 'ARM' in cpu_info:
                        return "Jetson"
            except:
                pass
        return system
    
    def setup_tts(self):
        """í”Œë«í¼ë³„ TTS ì„¤ì •"""
        if self.platform == "Jetson":
            # ì ¯ìŠ¨ ì „ìš© TTS ì„¤ì • (gTTS ìš°ì„ , Festival ë°±ì—…, espeak ìµœì¢…)
            self.tts_method = "gtts"
            self.backup_tts = "festival"
            print("TTS: ì ¯ìŠ¨ Google TTS ìš°ì„  ì‚¬ìš© (í•œêµ­ì–´ í’ˆì§ˆ ìµœê³ )")
            print("ë°±ì—… TTS: Festival TTS")
            print("ìµœì¢… ë°±ì—…: espeak TTS")
        elif self.platform == "Darwin":  # macOS
            self.tts_method = "gtts"
            self.backup_tts = "native_say"
            print("TTS: Google TTS ìš°ì„  ì‚¬ìš©")
            print("ë°±ì—… TTS: macOS say ëª…ë ¹ì–´")
        elif self.platform == "Windows":
            self.tts_method = "gtts"
            self.backup_tts = "pyttsx3"
            print("TTS: Google TTS ìš°ì„  ì‚¬ìš©")
            print("ë°±ì—… TTS: Windows pyttsx3")
        elif self.platform == "Linux":
            self.tts_method = "gtts"
            self.backup_tts = "festival"
            print("TTS: Google TTS ìš°ì„  ì‚¬ìš©")
            print("ë°±ì—… TTS: Festival TTS")
        else:
            self.tts_method = "gtts"
            self.backup_tts = "pyttsx3"
            print("TTS: Google TTS ìš°ì„  ì‚¬ìš©")
            print("ë°±ì—… TTS: pyttsx3")
    
    def _feedback_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ TTS í”¼ë“œë°±ì„ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                feedback_data = self.feedback_queue.get(timeout=1.0)
                if feedback_data:
                    message, priority = feedback_data
                    self._speak_feedback(message, priority)
                self.feedback_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"TTS í”¼ë“œë°± ì˜¤ë¥˜: {e}")
    
    def _speak_feedback(self, message: str, priority: str):
        """í”Œë«í¼ë³„ TTS ì‚¬ìš©"""
        try:
            if self.platform == "Jetson":
                # ì ¯ìŠ¨ gTTS ìš°ì„  ì‹œë„
                self._speak_gtts(message, priority)
            elif self.tts_method == "gtts":
                # Google TTS ìš°ì„  ì‹œë„
                self._speak_gtts(message, priority)
            else:
                # ê¸°ë³¸ TTS ì‹œë„
                self._speak_backup(message)
        except Exception as e:
            print(f"ì£¼ TTS ì‹¤íŒ¨: {e}")
            # í”Œë«í¼ë³„ ë°±ì—… TTS ì‹œë„
            self._speak_backup(message)
    
    def _speak_gtts(self, message: str, priority: str):
        """Google TTS ë©”ì¸ (ìš°ì„  ì‚¬ìš©)"""
        try:
            from gtts import gTTS
            tts = gTTS(text=message, lang='ko')
            temp_file = "temp_speech.mp3"
            tts.save(temp_file)
            
            # í”Œë«í¼ë³„ ì˜¤ë””ì˜¤ ì¬ìƒ
            if self.platform == "Darwin":  # macOS
                subprocess.run(['afplay', temp_file], check=True)
            elif self.platform == "Windows":
                os.startfile(temp_file)  # Windows ê¸°ë³¸ í”Œë ˆì´ì–´
            elif self.platform in ["Linux", "Jetson"]:
                # Linux/ì ¯ìŠ¨ì—ì„œ MP3 ì¬ìƒì„ ìœ„í•œ ì—¬ëŸ¬ ë°©ë²• ì‹œë„
                self._play_mp3_linux(temp_file)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.remove(temp_file)
            print("Google TTS ì‚¬ìš©ë¨")
            
        except ImportError:
            print("gTTSê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°±ì—… TTSë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            raise
        except Exception as e:
            print(f"Google TTS ì‹¤íŒ¨: {e}")
            raise
    
    def _play_mp3_linux(self, mp3_file: str):
        """Linux/ì ¯ìŠ¨ì—ì„œ MP3 íŒŒì¼ ì¬ìƒ"""
        # ì—¬ëŸ¬ MP3 í”Œë ˆì´ì–´ ì¤‘ í•˜ë‚˜ë¥¼ ì°¾ì•„ì„œ ì‚¬ìš©
        players = [
            ('mpg123', ['mpg123', mp3_file]),
            ('ffplay', ['ffplay', '-nodisp', '-autoexit', mp3_file]),
            ('mpv', ['mpv', '--no-video', mp3_file]),
            ('cvlc', ['cvlc', '--play-and-exit', mp3_file])
        ]
        
        for player_name, cmd in players:
            try:
                subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                print(f"MP3 ì¬ìƒ: {player_name} ì‚¬ìš©")
                return
            except (subprocess.CalledProcessError, FileNotFoundError):
                continue
        
        # MP3 í”Œë ˆì´ì–´ê°€ ì—†ìœ¼ë©´ WAVë¡œ ë³€í™˜ í›„ ì¬ìƒ
        try:
            import pydub
            audio = pydub.AudioSegment.from_mp3(mp3_file)
            wav_file = mp3_file.replace('.mp3', '.wav')
            audio.export(wav_file, format="wav")
            subprocess.run(['aplay', wav_file], check=True)
            os.remove(wav_file)
            print("MP3ë¥¼ WAVë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ")
        except ImportError:
            print("pydubê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ MP3ë¥¼ WAVë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            raise Exception("Linuxì—ì„œ MP3 ì¬ìƒì„ ìœ„í•œ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    def _speak_backup(self, message: str):
        """í”Œë«í¼ë³„ ë°±ì—… TTS"""
        try:
            if self.platform == "Darwin":  # macOS
                subprocess.run(['say', '-r', '150', message], check=True)
            elif self.platform == "Windows":
                import pyttsx3
                engine = pyttsx3.init()
                engine.setProperty('rate', 150)
                engine.say(message)
                engine.runAndWait()
            elif self.platform in ["Linux", "Jetson"]:
                subprocess.run(['espeak', '-s', '120', message], check=True)
            print(f"ë°±ì—… TTS ì‚¬ìš©ë¨")
            
        except Exception as e:
            print(f"ë°±ì—… TTSë„ ì‹¤íŒ¨: {e}")
            print("ìŒì„± í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def add_feedback(self, error_type: str, priority: str = "normal"):
        """ì§€ëŠ¥ì  í”¼ë“œë°± ì¶”ê°€ (ì”ì†Œë¦¬ê¾¼ ë°©ì§€)"""
        current_time = time.time()
        
        # ê°™ì€ ì˜¤ë¥˜ì— ëŒ€í•œ ì¿¨ë‹¤ìš´ ì²´í¬
        if error_type in self.last_feedback_time:
            if current_time - self.last_feedback_time[error_type] < self.feedback_cooldown:
                return False
        
        # ìµœì†Œ í”¼ë“œë°± ê°„ê²© ì²´í¬
        if current_time - self.last_general_feedback < self.min_feedback_interval:
            return False
        
        # ì˜¤ë¥˜ê°€ 2ê°œ ì´ìƒì¼ ë•ŒëŠ” ìš°ì„ ìˆœìœ„ 1ìœ„ë§Œ í”¼ë“œë°± (ì”ì†Œë¦¬ê¾¼ ë°©ì§€)
        if hasattr(self, 'current_hold_errors') and len(self.current_hold_errors) >= 2:
            priority_errors = self.get_priority_order(self.current_hold_errors)
            if error_type != priority_errors[0]:  # ìš°ì„ ìˆœìœ„ 1ìœ„ë§Œ
                return False
        
        # í”¼ë“œë°± ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        message = self.feedback_messages.get(error_type, f"{error_type}ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
        
        # í”¼ë“œë°± íì— ì¶”ê°€
        self.feedback_queue.put((message, priority))
        
        # ì‹œê°„ ì—…ë°ì´íŠ¸
        self.last_feedback_time[error_type] = current_time
        self.last_general_feedback = current_time
        
        return True
    
    def get_priority_order(self, errors: List[str]) -> List[str]:
        """ì˜¤ë¥˜ë¥¼ ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ì •ë ¬ (ì•ˆì „ì„± > íš¨ê³¼ì„± > ìµœì í™”)"""
        priority_order = [
            "ì—‰ë©ì´ ì²˜ì§",        # ğŸš¨ ì•ˆì „ì„± ìµœìš°ì„ 
            "ì—‰ë©ì´ ì†ŸìŒ",        # ğŸš¨ ì•ˆì „ì„± ìµœìš°ì„   
            "ê³ ê°œ ì •ë ¬ ë¶ˆëŸ‰",     # âš ï¸ íš¨ê³¼ì„±
            "íŒ”ê¿ˆì¹˜ ì •ë ¬ ë¶ˆëŸ‰",   # âš ï¸ íš¨ê³¼ì„±
            "ë¬´ë¦ êµ½í˜"          # ğŸ’¡ ìµœì í™”
        ]
        
        # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ì •ë ¬
        sorted_errors = []
        for priority_error in priority_order:
            if priority_error in errors:
                sorted_errors.append(priority_error)
        
        return sorted_errors
    
    def add_encouragement(self, hold_time: float):
        """ê²©ë ¤ ë©”ì‹œì§€ ì¶”ê°€"""
        current_time = time.time()
        if current_time - self.last_general_feedback < 10.0:  # 10ì´ˆ ê°„ê²©
            return
        
        encouragements = [
            "ì˜ í•˜ê³  ìˆìŠµë‹ˆë‹¤!",
            "ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”!",
            "í•œ ë²ˆ ë” í˜ë‚´ì„¸ìš”!",
            "í›Œë¥­í•©ë‹ˆë‹¤!"
        ]
        
        message = encouragements[int(hold_time) % len(encouragements)]
        self.feedback_queue.put((message, "encouragement"))
        self.last_general_feedback = current_time
    
    def stop(self):
        """TTS ë§¤ë‹ˆì € ì •ë¦¬"""
        self.running = False
        self.feedback_thread.join(timeout=1.0)

    def _check_jetson_tts_tools(self):
        """ì ¯ìŠ¨ì—ì„œ í•„ìš”í•œ TTS ë„êµ¬ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì•ˆë‚´"""
        print("\n" + "="*60)
        print("ì ¯ìŠ¨ TTS ë„êµ¬ ì„¤ì¹˜ í™•ì¸ ì¤‘...")
        print("="*60)
        
        tools_status = {}
        
        # Google TTS í™•ì¸ (í•œêµ­ì–´ í’ˆì§ˆ ìµœê³ )
        try:
            import gtts
            tools_status['Google TTS (gTTS)'] = "âœ… ì„¤ì¹˜ë¨ (í•œêµ­ì–´ í’ˆì§ˆ ìµœê³ )"
        except ImportError:
            tools_status['Google TTS (gTTS)'] = "âŒ ì„¤ì¹˜ í•„ìš” (1ìˆœìœ„)"
        
        # espeak TTS í™•ì¸ (ìµœì¢… ë°±ì—…)
        try:
            subprocess.run(['espeak', '--version'], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            tools_status['espeak TTS'] = "âœ… ì„¤ì¹˜ë¨ (ìµœì¢… ë°±ì—…)"
        except:
            tools_status['espeak TTS'] = "âŒ ì„¤ì¹˜ í•„ìš”"
        
        # MP3 ì¬ìƒ ë„êµ¬ í™•ì¸
        mp3_players = ['mpg123', 'ffplay', 'mpv', 'cvlc']
        mp3_status = "âŒ ì„¤ì¹˜ í•„ìš”"
        for player in mp3_players:
            try:
                subprocess.run([player, '--help'], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                mp3_status = f"âœ… {player} ì‚¬ìš© ê°€ëŠ¥"
                break
            except:
                continue
        tools_status['MP3 Player'] = mp3_status
        
        # ìƒíƒœ ì¶œë ¥
        for tool, status in tools_status.items():
            print(f"{tool}: {status}")
        
        # ì„¤ì¹˜ ì•ˆë‚´
        if any("âŒ" in status for status in tools_status.values()):
            print("\nğŸ“‹ ì ¯ìŠ¨ì—ì„œ TTS ë„êµ¬ ì„¤ì¹˜ ë°©ë²•:")
            print("\nğŸ¥‡ Google TTS (1ìˆœìœ„, í•œêµ­ì–´ í’ˆì§ˆ ìµœê³ ):")
            print("pip install gtts pydub")
            
            print("\nğŸ¥ˆ ê¸°ë³¸ TTS ë„êµ¬ë“¤ (2ìˆœìœ„):")
            print("sudo apt-get update")
            print("sudo apt-get install espeak")                      # espeak TTS
            print("sudo apt-get install mpg123")                      # MP3 ì¬ìƒ
            
            print("\nğŸ“¦ Python íŒ¨í‚¤ì§€:")
            print("pip install gtts pydub numpy")
        
        print("="*60 + "\n")

def calculate_angle(a: list, b: list, c: list) -> float:
    """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ê²°ê³¼ê°’: 0-180)"""
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    
    if angle > 180.0:
        angle = 360 - angle
        
    return angle

class ComprehensivePlankGrader:
    """
    'AI í”Œë­í¬ ìì„¸ êµì •ì„ ìœ„í•œ ì¢…í•© í‰ê°€ ê¸°ì¤€'ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ìƒˆë¡œìš´ í‰ê°€ í´ë˜ìŠ¤.
    ê³„ì¸µì  í”¼ë“œë°± êµ¬ì¡°(ì•ˆì „ì„± > íš¨ê³¼ì„± > ìµœì í™”)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
    """
    def __init__(self):
        pass

    def evaluate_errors(self, angles: dict, landmarks: dict) -> List[str]:
        """
        ìì„¸ë¥¼ í‰ê°€í•˜ê³  ë°œìƒí•œ ëª¨ë“  ì˜¤ë¥˜ ëª©ë¡ì„ ê³„ì¸µì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        errors = []
        
        # ë ˆë²¨ 1: ì•ˆì „ì„± (Safety) - ì¦‰ì‹œ êµì • ëŒ€ìƒ
        if 'body' in angles and angles['body'] > 200: # 190 -> 200
            errors.append("ì—‰ë©ì´ ì²˜ì§")

        # ë ˆë²¨ 2: íš¨ê³¼ì„± (Effectiveness) - ì£¼ìš” êµì • ëŒ€ìƒ
        if 'body' in angles and angles['body'] < 150: # 165 -> 150
            errors.append("ì—‰ë©ì´ ì†ŸìŒ")
        if 'neck' in angles and not (150 <= angles['neck'] <= 210): # 165-195 -> 150-210
            errors.append("ê³ ê°œ ì •ë ¬ ë¶ˆëŸ‰")

        # ë ˆë²¨ 3: ìµœì í™” (Optimization) - ë¯¸ì„¸ ì¡°ì •
        is_elbow_misaligned = 'arm' in angles and not (60 <= angles['arm'] <= 120) # 75-105 -> 60-120
        # íŒ”ê¿ˆì¹˜ê°€ ì–´ê¹¨ë³´ë‹¤ ë„ˆë¬´ ì•ì´ë‚˜ ë’¤ì— ìˆëŠ”ì§€ í™•ì¸
        shoulder_x = (landmarks['left_shoulder'][0] + landmarks['right_shoulder'][0]) / 2
        elbow_x = (landmarks['left_elbow'][0] + landmarks['right_elbow'][0]) / 2
        shoulder_hip_dist = abs(landmarks['left_shoulder'][0] - landmarks['left_hip'][0]) # ê¸°ì¤€ ê±°ë¦¬
        is_elbow_pos_off = abs(shoulder_x - elbow_x) > shoulder_hip_dist * 0.40 # 0.20 -> 0.40

        if is_elbow_misaligned or is_elbow_pos_off:
            errors.append("íŒ”ê¿ˆì¹˜ ì •ë ¬ ë¶ˆëŸ‰")
            
        if 'leg' in angles and angles['leg'] < 150: # 165 -> 150
            errors.append("ë¬´ë¦ êµ½í˜")

        return errors

    def get_grade_from_errors(self, errors: List[str]) -> str:
        """ì˜¤ë¥˜ ê°œìˆ˜ì— ë”°ë¼ ë“±ê¸‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        num_errors = len(set(errors))
        if num_errors == 0: return "A"
        elif num_errors == 1: return "B"
        elif num_errors == 2: return "C"
        elif num_errors == 3: return "D"
        else: return "F"

    def get_error_priority(self, error: str) -> str:
        """ì˜¤ë¥˜ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        safety_errors = ["ì—‰ë©ì´ ì²˜ì§", "ì—‰ë©ì´ ì†ŸìŒ"]
        if error in safety_errors:
            return "urgent"
        return "normal"

# ì˜¤ë¥˜ í‚¤ì™€ ìƒì„¸ ì„¤ëª…ì„ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
ERROR_CRITERIA_MAP = {
    "ì—‰ë©ì´ ì²˜ì§": "ì—‰ë©ì´ ì²˜ì§ (Hip Sag / í—ˆë¦¬ êº¾ì„): ì½”ì–´ì™€ ë‘”ê·¼ì˜ í˜ì´ í’€ë ¤ í—ˆë¦¬ê°€ Uìë¡œ êº¾ì´ëŠ” í˜„ìƒ.",
    "ì—‰ë©ì´ ì†ŸìŒ": "ì—‰ë©ì´ ì†ŸìŒ (Hip Pike): ì½”ì–´ì˜ ë¶€ë‹´ì„ ì¤„ì´ê¸° ìœ„í•´ ì—‰ë©ì´ë¥¼ ê³¼ë„í•˜ê²Œ ë†’ì´ ë“œëŠ” ìì„¸.",
    "ê³ ê°œ ì •ë ¬ ë¶ˆëŸ‰": "ê³ ê°œ ë–¨êµ¼ / ì –í˜ (Head/Neck Misalignment): ëª©ì´ ì²™ì¶”ì˜ ì¤‘ë¦½ì„ ì—ì„œ ë²—ì–´ë‚˜ëŠ” ìì„¸.",
    "íŒ”ê¿ˆì¹˜ ì •ë ¬ ë¶ˆëŸ‰": "íŒ”ê¿ˆì¹˜/ì†ëª© ì •ë ¬ ë¶ˆëŸ‰ (Elbow/Wrist Misalignment): íŒ”ê¿ˆì¹˜ê°€ ì–´ê¹¨ ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜í•˜ì§€ ì•ŠëŠ” ìì„¸.",
    "ë¬´ë¦ êµ½í˜": "ë¬´ë¦ êµ½í˜ (Knee Bend): ë‹¤ë¦¬ì˜ ê¸´ì¥ì´ í’€ë ¤ ë¬´ë¦ì´ êµ½í˜€ì§€ëŠ” í˜„ìƒ."
}

def save_report(report_path: str, hold_results: List[Dict]):
    """ë¶„ì„ ê²°ê³¼ì™€ ì „ì²´ í‰ê°€ ê¸°ì¤€ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    total_hold_time = sum(res['duration'] for res in hold_results)

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("ì‹¤ì‹œê°„ í”Œë­í¬ ìì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ (TTS í”¼ë“œë°± í¬í•¨)\n")
        f.write("="*50 + "\n")
        f.write(f"ì´ í”Œë­í¬ ìœ ì§€ ì‹œê°„: {total_hold_time:.2f}ì´ˆ\n\n")
        
        f.write("êµ¬ê°„ë³„ ìƒì„¸ ê²°ê³¼:\n")
        if not hold_results:
            f.write("- í”Œë­í¬ ìì„¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n")
        
        for i, res in enumerate(hold_results):
            grade = res['grade']
            duration = res['duration']
            errors = res['errors']
            f.write(f"\n--- {i+1}ë²ˆì§¸ êµ¬ê°„ (ìœ ì§€ ì‹œê°„: {duration:.2f}ì´ˆ): ë“±ê¸‰ {grade} ---\n")
            if errors:
                f.write("  [ì£¼ìš” ë°œìƒ ì˜¤ë¥˜]\n")
                # ê°€ì¥ ë§ì´ ë°œìƒí•œ ì˜¤ë¥˜ ìˆœìœ¼ë¡œ ì •ë ¬
                sorted_errors = sorted(errors.items(), key=lambda item: item[1], reverse=True)
                for error_key, count in sorted_errors:
                    error_description = ERROR_CRITERIA_MAP.get(error_key, "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    f.write(f"  - {error_description} ({count}íšŒ ê°ì§€)\n")
            else:
                f.write("  - ëª¨ë“  ê¸°ì¤€ì„ ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.\n")

        # ì „ì²´ í‰ê°€ ê¸°ì¤€ ì¶”ê°€
        f.write("\n\n" + "="*50 + "\n")
        f.write("          ìì„¸ í‰ê°€ ê¸°ì¤€ (ì°¸ê³ )\n")
        f.write("="*50 + "\n\n")

        f.write("1. í”Œë­í¬ (Plank) ì¢…í•© ê¸°ì¤€\n")
        f.write("-------------------------\n")
        f.write("ë ˆë²¨ 1: ì•ˆì „ì„± (Safety) - ì¦‰ì‹œ êµì • ëŒ€ìƒ\n")
        f.write("- ì—‰ë©ì´ ì²˜ì§ (Hip Sag / í—ˆë¦¬ êº¾ì„): ì–´ê¹¨-ì—‰ë©ì´-ë°œëª© ê°ë„ > 200ë„\n\n")
        f.write("ë ˆë²¨ 2: íš¨ê³¼ì„± (Effectiveness) - ì£¼ìš” êµì • ëŒ€ìƒ\n")
        f.write("- ì—‰ë©ì´ ì†ŸìŒ (Hip Pike): ì–´ê¹¨-ì—‰ë©ì´-ë°œëª© ê°ë„ < 150ë„\n")
        f.write("- ê³ ê°œ ë–¨êµ¼ / ì –í˜ (Head/Neck Misalignment): ê·€-ì–´ê¹¨-ì—‰ë©ì´ ê°ë„ê°€ 150ë„~210ë„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨\n\n")
        f.write("ë ˆë²¨ 3: ìµœì í™” (Optimization) - ë¯¸ì„¸ ì¡°ì •\n")
        f.write("- íŒ”ê¿ˆì¹˜/ì†ëª© ì •ë ¬ ë¶ˆëŸ‰ (Elbow/Wrist Misalignment): ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª© ê°ë„ê°€ 60ë„~120ë„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ê±°ë‚˜, íŒ”ê¿ˆì¹˜ê°€ ì–´ê¹¨ ìˆ˜ì§ì„ ìƒì—ì„œ ë²—ì–´ë‚¨\n")
        f.write("- ë¬´ë¦ êµ½í˜ (Knee Bend): ê³ ê´€ì ˆ-ë¬´ë¦-ë°œëª© ê°ë„ < 150ë„\n\n")

    print(f"ë¦¬í¬íŠ¸ê°€ '{report_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def run_plank_analysis(duration_seconds=120, stop_callback=None):
    """ì‹¤ì‹œê°„ ì¹´ë©”ë¼ë¥¼ í†µí•œ í”Œë­í¬ ë¶„ì„ í•¨ìˆ˜ (TTS í”¼ë“œë°± í¬í•¨)
    
    Args:
        duration_seconds (int): ë¶„ì„í•  ì‹œê°„ (ì´ˆ), ê¸°ë³¸ê°’ 120ì´ˆ (2ë¶„)
        stop_callback (callable): ë¶„ì„ ì¤‘ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ì½œë°± í•¨ìˆ˜
    """
    
    # ì¤‘ì§€ í”Œë˜ê·¸ ì´ˆê¸°í™”
    run_plank_analysis._stop_analysis = False

    try:
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        print("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘...")
        cap = cv2.VideoCapture(0)  # ê¸°ë³¸ ì¹´ë©”ë¼ (ë³´í†µ ë‚´ì¥ ì›¹ìº )
        
        if not cap.isOpened():
            print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        # ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
        print("ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸ ì¤‘...")
        ret, test_frame = cap.read()
        if not ret:
            print("ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            cap.release()
            return None, None
        
        print(f"ì¹´ë©”ë¼ ì„±ê³µ: {test_frame.shape}")
        
    except Exception as e:
        print(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None, None
    
    # ì¹´ë©”ë¼ ì„¤ì •
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    # ì˜ìƒ ì €ì¥ì„ ìœ„í•œ ì„¤ì •
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = 30.0
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    
    # output ë””ë ‰í† ë¦¬ ìƒì„± ë° í™•ì¸ (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "output")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"output ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {output_dir}")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª… ìƒì„± (output ë””ë ‰í† ë¦¬ ë‚´)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_video_path = os.path.join(output_dir, f"plank_realtime_tts_analysis_{timestamp}.mp4")
    output_report_path = os.path.join(output_dir, f"plank_realtime_tts_report_{timestamp}.txt")
    
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))
    
    try:
        # TTS í”¼ë“œë°± ë§¤ë‹ˆì € ì´ˆê¸°í™”
        print("TTS ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        tts_manager = UniversalTTS()
        
        # í”Œë­í¬ ë“±ê¸‰ í‰ê°€ê¸° ì´ˆê¸°í™”
        print("í”Œë­í¬ ë“±ê¸‰ í‰ê°€ê¸° ì´ˆê¸°í™” ì¤‘...")
        grader = ComprehensivePlankGrader()
        
        # ë³€ìˆ˜ ì´ˆê¸°í™”
        all_hold_results = []
        current_hold_errors = GradeCounter()
        is_holding = False
        hold_start_time = 0
        current_grade = "N/A"
        
        print("ì´ˆê¸°í™” ì™„ë£Œ!")
        
    except Exception as e:
        print(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        cap.release()
        out.release()
        return None, None
    
    # íƒ€ì´ë¨¸ ì„¤ì •
    start_time = time.time()
    recording_duration = duration_seconds
    
    print(f"í”Œë­í¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. {duration_seconds}ì´ˆê°„ ì¹´ë©”ë¼ê°€ ì¼œì§‘ë‹ˆë‹¤.")
    print("TTS í”¼ë“œë°±ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤!")
    print("í”Œë­í¬ ìì„¸ë¥¼ ì·¨í•˜ì„¸ìš”!")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    
    # ì‹œì‘ ì•ˆë‚´ ë©”ì‹œì§€
    tts_manager.add_feedback("ì‹œì‘", "encouragement")
    
    while cap.isOpened():
        try:
            ret, frame = cap.read()
            if not ret: 
                print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # í˜„ì¬ ì‹œê°„ ê³„ì‚°
            current_time = time.time()
            elapsed_time = current_time - start_time
            remaining_time = max(0, recording_duration - elapsed_time)
            
            # ì‹œê°„ ê²½ê³¼ ì‹œ ì¢…ë£Œ
            if elapsed_time >= recording_duration:
                print(f"ì„¤ì •ëœ ì‹œê°„ {duration_seconds}ì´ˆê°€ ê²½ê³¼í–ˆìŠµë‹ˆë‹¤.")
                break
            
            try:
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                results = pose.process(image)
                image.flags.writeable = True
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            except Exception as e:
                print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
                
        except Exception as e:
            print(f"ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜: {str(e)}")
            break
        
        # í¬ì¦ˆ ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš° ê±´ë„ˆë›°ê¸°
        if not results.pose_landmarks:
            print("í¬ì¦ˆ ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì•ì— ì‚¬ëŒì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            continue
            
        try:
            landmarks = results.pose_landmarks.landmark
            h, w, _ = image.shape
            
            lm_data = {
                'left_shoulder': [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y * h],
                'left_hip': [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y * h],
                'left_knee': [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y * h],
                'left_ankle': [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y * h],
                'left_ear': [landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_EAR.value].y * h],
                'left_elbow': [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y * h],
                'left_wrist': [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x * w, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y * h],
                'right_shoulder': [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * h],
                'right_hip': [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y * h],
                'right_knee': [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y * h],
                'right_ankle': [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y * h],
                'right_ear': [landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_EAR.value].y * h],
                'right_elbow': [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y * h],
                'right_wrist': [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x * w, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y * h],
            }

            # í”Œë­í¬ ìì„¸ ê¸°ë³¸ ì¡°ê±´ í™•ì¸
            shoulder_y = (lm_data['left_shoulder'][1] + lm_data['right_shoulder'][1]) / 2
            hip_y = (lm_data['left_hip'][1] + lm_data['right_hip'][1]) / 2
            if shoulder_y < hip_y + 50: # ì–´ê¹¨ê°€ ì—‰ë©ì´ë³´ë‹¤ ë„ˆë¬´ ë‚®ì§€ ì•Šì€ì§€ (ì—ë“œë¦° ìì„¸ í™•ì¸)
                is_plank_pose = True
            else:
                is_plank_pose = False

            if is_plank_pose:
                # ê°ë„ ê³„ì‚°
                angles = {}
                use_left_side = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].visibility > landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].visibility
                if use_left_side:
                    angles['body'] = calculate_angle(lm_data['left_shoulder'], lm_data['left_hip'], lm_data['left_ankle'])
                    angles['neck'] = calculate_angle(lm_data['left_ear'], lm_data['left_shoulder'], lm_data['left_hip'])
                    angles['arm'] = calculate_angle(lm_data['left_shoulder'], lm_data['left_elbow'], lm_data['left_wrist'])
                    angles['leg'] = calculate_angle(lm_data['left_hip'], lm_data['left_knee'], lm_data['left_ankle'])
                else:
                    angles['body'] = calculate_angle(lm_data['right_shoulder'], lm_data['right_hip'], lm_data['right_ankle'])
                    angles['neck'] = calculate_angle(lm_data['right_ear'], lm_data['right_shoulder'], lm_data['right_hip'])
                    angles['arm'] = calculate_angle(lm_data['right_shoulder'], lm_data['right_elbow'], lm_data['right_wrist'])
                    angles['leg'] = calculate_angle(lm_data['right_hip'], lm_data['right_knee'], lm_data['right_ankle'])
                
                # í”Œë­í¬ ìœ ì§€ ìƒíƒœ ê´€ë¦¬
                if not is_holding:
                    is_holding = True
                    hold_start_time = time.time()
                    current_hold_errors.clear()

                # ì˜¤ë¥˜ í‰ê°€
                errors_in_frame = grader.evaluate_errors(angles, lm_data)
                
                # í˜„ì¬ ë“±ê¸‰ ê³„ì‚°í•˜ì—¬ TTS ë§¤ë‹ˆì €ì— ì „ë‹¬
                current_grade = grader.get_grade_from_errors(list(current_hold_errors.keys()))
                tts_manager.current_grade = current_grade
                tts_manager.current_hold_errors = current_hold_errors
                
                # ìƒˆë¡œìš´ ì˜¤ë¥˜ì— ëŒ€í•´ì„œë§Œ TTS í”¼ë“œë°± ì œê³µ
                for error in errors_in_frame:
                    if error not in current_hold_errors:
                        priority = grader.get_error_priority(error)
                        tts_manager.add_feedback(error, priority)
                
                current_hold_errors.update(errors_in_frame)
                current_grade = grader.get_grade_from_errors(list(current_hold_errors.keys()))

            elif is_holding: # í”Œë­í¬ ìì„¸ê°€ ê¹¨ì¡Œì„ ë•Œ
                is_holding = False
                hold_duration = time.time() - hold_start_time
                if hold_duration > 1: # 1ì´ˆ ì´ìƒ ìœ ì§€í–ˆì„ ë•Œë§Œ ê¸°ë¡
                    final_grade = grader.get_grade_from_errors(list(current_hold_errors.keys()))
                    all_hold_results.append({
                        'duration': hold_duration,
                        'grade': final_grade,
                        'errors': current_hold_errors
                    })

        except Exception as e:
            pass
        
        # ------------------ í™”ë©´ í‘œì‹œ ì •ë³´ ìˆ˜ì • ------------------
        # ìƒë‹¨ ì •ë³´ ë°•ìŠ¤
        cv2.rectangle(image, (0,0), (frame_width, 120), (245,117,16), -1)
        
        # íƒ€ì´ë¨¸ í‘œì‹œ
        cv2.putText(image, f'TIME: {remaining_time:.1f}s', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)
        
        # STATUS
        status_text = "HOLDING" if is_holding else "READY"
        status_color = (0, 255, 0) if is_holding else (0, 0, 255)
        cv2.putText(image, 'STATUS', (int(frame_width * 0.3), 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)
        cv2.putText(image, status_text, (int(frame_width * 0.3), 65), cv2.FONT_HERSHEY_SIMPLEX, 1.5, status_color, 3, cv2.LINE_AA)
        
        # HOLD TIME
        hold_time = (time.time() - hold_start_time) if is_holding else 0
        cv2.putText(image, 'HOLD TIME', (int(frame_width * 0.5), 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)
        cv2.putText(image, f"{hold_time:.1f}s", (int(frame_width * 0.5), 65), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 3, cv2.LINE_AA)

        # GRADE
        cv2.putText(image, 'GRADE', (int(frame_width * 0.7), 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)
        cv2.putText(image, current_grade, (int(frame_width * 0.7), 65), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 3, cv2.LINE_AA)
        
        # TTS ìƒíƒœ í‘œì‹œ
        cv2.putText(image, 'TTS: ON', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2, cv2.LINE_AA)
        
        # í•˜ë‹¨ ì•ˆë‚´ ë©”ì‹œì§€
        cv2.rectangle(image, (0, frame_height-50), (frame_width, frame_height), (0,0,0), -1)
        cv2.putText(image, 'Press Q to quit early | TTS Feedback Active', (10, frame_height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2, cv2.LINE_AA)
        # ----------------------------------------------------
        
        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), 
                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))               
        
        out.write(image)
        
        # macOSì—ì„œëŠ” GUI ì—†ì´ ì½˜ì†” ëª¨ë“œë¡œ ì‹¤í–‰
        print(f"í”„ë ˆì„ ì²˜ë¦¬ ì¤‘... STATUS: {'HOLDING' if is_holding else 'READY'}, TIME: {hold_time:.1f}s, GRADE: {current_grade}")

        # OpenCV ì°½ í‘œì‹œ (ì ¯ìŠ¨ì—ì„œë§Œ í™œì„±í™”, macOSì—ì„œëŠ” ë¹„í™œì„±í™”)
        # try:
        #     cv2.namedWindow('Real-time Plank Analysis with TTS', cv2.WINDOW_NORMAL)
        #     cv2.resizeWindow('Real-time Plank Analysis with TTS', 1280, 720)
        # except Exception as e:
        #     print(f"ì°½ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ì°½ ì‚¬ìš©: {e}")
        
        # try:
        #     cv2.imshow('Real-time Plank Analysis with TTS', image)
        # except Exception as e:
        #     print(f"ì´ë¯¸ì§€ í‘œì‹œ ì‹¤íŒ¨: {e}")

        # í”Œë«í¼ë³„ OpenCV ì°½ í‘œì‹œ
        import platform
        system = platform.system()
        
        # ì ¯ìŠ¨ ê°ì§€ (ARM64 + Linux)
        is_jetson = False
        if system == "Linux":
            try:
                with open('/proc/cpuinfo', 'r') as f:
                    cpu_info = f.read()
                    if 'aarch64' in cpu_info or 'ARM' in cpu_info:
                        is_jetson = True
            except:
                pass
        
        # ì ¯ìŠ¨ì—ì„œë§Œ ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ
        if is_jetson:
            try:
                cv2.namedWindow('Real-time Plank Analysis with TTS', cv2.WINDOW_NORMAL)
                cv2.resizeWindow('Real-time Plank Analysis with TTS', 1280, 720)
                cv2.imshow('Real-time Plank Analysis with TTS', image)
                
                # ì ¯ìŠ¨ì—ì„œëŠ” í‚¤ ì…ë ¥ë„ ì²˜ë¦¬
                key = cv2.waitKey(10) & 0xFF
                if key == ord('q'): 
                    print("ì‚¬ìš©ìê°€ 'q'ë¥¼ ëˆŒëŸ¬ ë¶„ì„ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                    break
                elif key == ord('s'):  # 's' í‚¤ë¡œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    screenshot_path = os.path.join(output_dir, f"screenshot_{timestamp}_{int(time.time())}.jpg")
                    cv2.imwrite(screenshot_path, image)
                    print(f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
                    
            except Exception as e:
                print(f"ì ¯ìŠ¨ OpenCV ì°½ ì˜¤ë¥˜: {e}")
        else:
            # macOS ë“±ì—ì„œëŠ” GUI ì—†ì´ ì‹¤í–‰
            time.sleep(0.01)  # 10ms ëŒ€ê¸°
        
        # ì‹œê°„ ê¸°ë°˜ ì¢…ë£Œ ì¡°ê±´ (ì˜ˆ: 5ì´ˆë§ˆë‹¤ ìƒíƒœ ì¶œë ¥)
        if int(time.time()) % 5 == 0 and int(time.time()) != getattr(locals(), '_last_status_time', 0):
            print(f"í”Œë­í¬ ë¶„ì„ ì§„í–‰ ì¤‘... ì‹œê°„: {remaining_time:.1f}ì´ˆ")
            _last_status_time = int(time.time())
        
        # ë¶„ì„ ì¤‘ì§€ ì²´í¬ (ì „ì—­ ë³€ìˆ˜ë¡œ ì œì–´)
        if hasattr(run_plank_analysis, '_stop_analysis') and run_plank_analysis._stop_analysis:
            print("ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break

        # ë¶„ì„ ì¤‘ì§€ ì²´í¬ (ì½œë°± í•¨ìˆ˜ë¡œ ì œì–´)
        if stop_callback and stop_callback():
            print("ë¶„ì„ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break

    # ë§ˆì§€ë§‰ í™€ë“œ ì„¸ì…˜ ì €ì¥
    if is_holding:
        hold_duration = time.time() - hold_start_time
        if hold_duration > 1:
            final_grade = grader.get_grade_from_errors(list(current_hold_errors.keys()))
            all_hold_results.append({
                'duration': hold_duration,
                'grade': final_grade,
                'errors': current_hold_errors
            })

    # TTS ë§¤ë‹ˆì € ì •ë¦¬
    tts_manager.stop()
    
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # ê²°ê³¼ ì €ì¥
    save_report(output_report_path, all_hold_results)
    print(f"ë¶„ì„ ì˜ìƒì´ '{output_video_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ë¶„ì„ ë¦¬í¬íŠ¸ê°€ '{output_report_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("TTS í”¼ë“œë°±ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
    return output_video_path, output_report_path

def main():
    """ê¸°ì¡´ main í•¨ìˆ˜ (í˜¸í™˜ì„± ìœ ì§€)"""
    video_path, report_path = run_plank_analysis(120)  # ê¸°ë³¸ 2ë¶„
    if video_path and report_path:
        print(f"ë¶„ì„ ì™„ë£Œ: {video_path}, {report_path}")
    else:
        print("ë¶„ì„ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
